#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, PointCloud2, PointField
from std_msgs.msg import Header
import numpy as np
from cv_bridge import CvBridge
from tf2_ros import Buffer, TransformListener, TransformException
from transforms3d.quaternions import quat2mat
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
import torch
import struct

class PointCloudBEVNode(Node):
    """
    Depth ì´ë¯¸ì§€ë¥¼ 3D Point Cloudì™€ BEV Mapìœ¼ë¡œ ë³€í™˜í•˜ê³  ë°œí–‰í•˜ëŠ” ë…¸ë“œ.
    ëª¨ë“  ì£¼ìš” ì—°ì‚°ì€ PyTorch CUDA GPU ê°€ì†ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        super().__init__('pointcloud_bev_node')

        # --- 1. ê¸°ë³¸ ëª¨ë“ˆ ì´ˆê¸°í™” ---
        self.bridge = CvBridge()
        self.device = torch.device('cuda')
        self.get_logger().info(f'ğŸš€ CUDA GPU ê°€ì† í™œì„±í™” (PyTorch, {self.device})')

        # --- 2. ROS íŒŒë¼ë¯¸í„° ì„ ì–¸ ---
        self.declare_parameter('depth_topic', '/camera/camera/depth/image_rect_raw')
        self.declare_parameter('pointcloud_topic', '/pointcloud')
        self.declare_parameter('source_frame', 'camera_depth_optical_frame')
        self.declare_parameter('target_frame', 'camera_link')

        # Intrinsic
        self.declare_parameter('cam.fx', 431.0625)
        self.declare_parameter('cam.fy', 431.0625)
        self.declare_parameter('cam.cx', 434.492)
        self.declare_parameter('cam.cy', 242.764)
        self.declare_parameter('cam.height', 480)
        self.declare_parameter('cam.width', 848)

        # PCL ë‹¤ìš´ìƒ˜í”Œë§
        self.declare_parameter('pcl.downsample_y', 3)
        self.declare_parameter('pcl.downsample_x', 2)

        # BEV íŒŒë¼ë¯¸í„°
        self.declare_parameter('bev_topic', '/bev_map')
        self.declare_parameter('bev.z_min', 0.1)
        self.declare_parameter('bev.z_max', 1.0)
        self.declare_parameter('bev.resolution', 0.05)
        self.declare_parameter('bev.size_x', 30.0)
        self.declare_parameter('bev.size_y', 40.0)

        # [NEW] ë¡œë´‡ ì•ˆì „ ì˜ì—­ ì„¤ì •ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° (BEV Gridê°€ ì´ ì˜ì—­ì„ í¬í•¨í•´ì•¼ í•¨)
        # ì¹´ë©”ë¼ê°€ (0,0)ì¼ ë•Œ ë¡œë´‡ì€ ë’¤ìª½ì— ìœ„ì¹˜í•˜ë¯€ë¡œ ìŒìˆ˜ ì¢Œí‘œ ì‚¬ìš©
        # ë¡œë´‡ í¬ê¸° 1m x 1m, ì¹´ë©”ë¼ê°€ ë¡œë´‡ ë§¨ ì• ì¤‘ì•™ì— ìˆë‹¤ê³  ê°€ì •
        self.declare_parameter('robot.safe_min_x', -1.0) # ì¹´ë©”ë¼ ë’¤ 1m
        self.declare_parameter('robot.safe_max_x', 0.0)  # ì¹´ë©”ë¼ ìœ„ì¹˜ê¹Œì§€
        self.declare_parameter('robot.safe_min_y', -0.5) # ì™¼ìª½ 0.5m
        self.declare_parameter('robot.safe_max_y', 0.5)  # ì˜¤ë¥¸ìª½ 0.5m

        # --- 3. íŒŒë¼ë¯¸í„° ê°’ í• ë‹¹ ---
        depth_topic = self.get_parameter('depth_topic').value
        pointcloud_topic = self.get_parameter('pointcloud_topic').value
        self.source_frame = self.get_parameter('source_frame').value
        self.target_frame = self.get_parameter('target_frame').value

        self.fx = self.get_parameter('cam.fx').value
        self.fy = self.get_parameter('cam.fy').value
        self.cx = self.get_parameter('cam.cx').value
        self.cy = self.get_parameter('cam.cy').value
        self.cam_height = self.get_parameter('cam.height').value
        self.cam_width = self.get_parameter('cam.width').value

        self.downsample_y = self.get_parameter('pcl.downsample_y').value
        self.downsample_x = self.get_parameter('pcl.downsample_x').value
    
        # BEV íŒŒë¼ë¯¸í„°
        bev_topic = self.get_parameter('bev_topic').value
        self.z_min = self.get_parameter('bev.z_min').value
        self.z_max = self.get_parameter('bev.z_max').value
        self.resolution = self.get_parameter('bev.resolution').value
        self.size_x = self.get_parameter('bev.size_x').value
        self.size_y = self.get_parameter('bev.size_y').value

        # BEV ê·¸ë¦¬ë“œ ì„¤ì •
        self.cells_x = int(self.size_x / self.resolution)
        self.cells_y = int(self.size_y / self.resolution)
        
        # [ì¤‘ìš” ë³€ê²½] ë¡œë´‡ì´ ì¹´ë©”ë¼ ë’¤ì— ìˆë‹¤ë©´, BEV ê·¸ë¦¬ë“œë„ ë’¤ìª½ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
        # ì˜ˆ: ê·¸ë¦¬ë“œ ì‹œì‘ì ì„ -5.0më¡œ ì„¤ì •í•˜ì—¬ ì¹´ë©”ë¼ ë’¤ìª½ë„ ë³´ì´ê²Œ í•¨
        # ë§Œì•½ 0.0ìœ¼ë¡œ ë‘ë©´ ë¡œë´‡ ë³¸ì²´ëŠ” ê·¸ë¦¬ë“œ ì•„ì˜ˆ ë°–ì— ì¡´ì¬í•˜ê²Œ ë©ë‹ˆë‹¤.
        # ì‚¬ìš©ìì˜ ì˜ë„ì— ë§ê²Œ "ë¡œë´‡ ì˜ì—­ì„ í‘œí˜„"í•˜ë ¤ë©´ ì›ì ì„ ë’¤ë¡œ ë‹¹ê²¨ì•¼ í•©ë‹ˆë‹¤.
        self.grid_origin_x = -2.0  # ì¹´ë©”ë¼ ë’¤ 2m ë¶€í„° ê·¸ë¦¬ë“œ ì‹œì‘ (ìˆ˜ì • ì œì•ˆ)
        self.grid_origin_y = -self.size_y / 2.0

        # --- 4. ROS í†µì‹  ì„¤ì • ---
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            history=HistoryPolicy.KEEP_LAST,
            depth=1
        )

        self.create_subscription(
            Image, depth_topic, self.depth_callback, qos_profile
        )
        self.pointcloud_pub = self.create_publisher(PointCloud2, pointcloud_topic, qos_profile)
        self.bev_pub = self.create_publisher(PointCloud2, bev_topic, qos_profile)

        # --- 5. Point Cloud í•„ë“œ ì •ì˜ ---
        self.pointcloud_fields = [
            PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
            PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1),
            PointField(name='z', offset=8, datatype=PointField.FLOAT32, count=1),
            PointField(name='rgb', offset=12, datatype=PointField.FLOAT32, count=1),
        ]
        self.point_step = 16

        # --- 6. GPU íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ---
        self._init_gpu_parameters()

        self.get_logger().info('âœ… PointCloud + BEV Node initialized (GPU Only)')
        self.get_logger().info(f"  BEV Grid Origin X: {self.grid_origin_x} m (Must be < 0 to see robot body)")




    def _init_gpu_parameters(self):
        """GPU íŒŒë¼ë¯¸í„° ë° Virtual Fence(ê²½ê³„ì„ )ê°€ ê·¸ë ¤ì§„ ê¸°ë³¸ ë§µ ìƒì„±"""
        # ... (ì´ì „ê³¼ ë™ì¼í•œ ê·¸ë¦¬ë“œ/íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”) ...
        # 1. PCL ì¬êµ¬ì„± ê·¸ë¦¬ë“œ
        v, u = torch.meshgrid(
            torch.arange(self.cam_height, device=self.device, dtype=torch.float32),
            torch.arange(self.cam_width, device=self.device, dtype=torch.float32),
            indexing='ij'
        )
        self.u_grid = u
        self.v_grid = v
        self.fx_tensor = torch.tensor(self.fx, device=self.device, dtype=torch.float32)
        self.fy_tensor = torch.tensor(self.fy, device=self.device, dtype=torch.float32)
        self.cx_tensor = torch.tensor(self.cx, device=self.device, dtype=torch.float32)
        self.cy_tensor = torch.tensor(self.cy, device=self.device, dtype=torch.float32)

        # 2. BEV íŒŒë¼ë¯¸í„°
        self.z_min_t = torch.tensor(self.z_min, device=self.device, dtype=torch.float32)
        self.z_max_t = torch.tensor(self.z_max, device=self.device, dtype=torch.float32)
        self.z_range_t = self.z_max_t - self.z_min_t
        self.resolution_t = torch.tensor(self.resolution, device=self.device, dtype=torch.float32)
        self.grid_origin_x_t = torch.tensor(self.grid_origin_x, device=self.device, dtype=torch.float32)
        self.grid_origin_y_t = torch.tensor(self.grid_origin_y, device=self.device, dtype=torch.float32)

        # --- [í•µì‹¬ ë³€ê²½] Virtual Fence ìƒì„± ì‹œì‘ ---

        # 3. ê¸°ë³¸ ë§µì„ 'Free(z_min)'ë¡œ ì´ˆê¸°í™” (2D í˜•íƒœë¡œ ì‘ì—… í›„ flatten)
        self.default_bev_grid = torch.full(
            (self.cells_y, self.cells_x),
            self.z_min, # ê¸°ë³¸ì€ ëª¨ë‘ ì£¼í–‰ ê°€ëŠ¥
            device=self.device,
            dtype=torch.float32
        )

        # 4. ë¡œë´‡ íœìŠ¤ (Robot Boundary Line) ê·¸ë¦¬ê¸°
        # ì›”ë“œ ì¢Œí‘œ -> ê·¸ë¦¬ë“œ ì¢Œí‘œ ë³€í™˜ í•¨ìˆ˜ (í´ë¨í•‘ í¬í•¨)
        def to_grid_x(world_x):
            idx = int((world_x-self.grid_origin_x)/ self.resolution)
            return max(0,min(idx,self.cells_x-1)) 
            # return torch.clamp(((world_x - self.grid_origin_x) / self.resolution).long(), 0, self.cells_x - 1)
        def to_grid_y(world_y): 
            idx = int((world_y-self.grid_origin_y)/ self.resolution)
            return max(0,min(idx,self.cells_y-1)) 
            # return torch.clamp(((world_y - self.grid_origin_y) / self.resolution).long(), 0, self.cells_y - 1)

        r_min_x = self.get_parameter('robot.safe_min_x').value
        r_max_x = self.get_parameter('robot.safe_max_x').value
        r_min_y = self.get_parameter('robot.safe_min_y').value
        r_max_y = self.get_parameter('robot.safe_max_y').value

        gx_min = to_grid_x(r_min_x); gx_max = to_grid_x(r_max_x)
        gy_min = to_grid_y(r_min_y); gy_max = to_grid_y(r_max_y)

        # í…Œë‘ë¦¬ ê·¸ë¦¬ê¸° (ìƒí•˜ì¢Œìš° ë¼ì¸)
        self.default_bev_grid[gy_min:gy_max+1, gx_min] = self.z_max_t # ë’¤ìª½ ë¼ì¸
        self.default_bev_grid[gy_min:gy_max+1, gx_max] = self.z_max_t # ì•ìª½ ë¼ì¸
        self.default_bev_grid[gy_min, gx_min:gx_max+1] = self.z_max_t # ì˜¤ë¥¸ìª½ ë¼ì¸
        self.default_bev_grid[gy_max, gx_min:gx_max+1] = self.z_max_t # ì™¼ìª½ ë¼ì¸

        # 5. FOV íœìŠ¤ (FOV Boundary Line) ê·¸ë¦¬ê¸°
        # ë¡œë´‡ ì¢Œí‘œê³„ ê¸°ì¤€: Xê°€ ì „ë°©, Yê°€ ì¢Œì¸¡
        # FOV ë¼ì¸ì„ ë”°ë¼ ì ë“¤ì„ ìƒì„±í•˜ê³  ê·¸ë¦¬ë“œì— ì°ìŠµë‹ˆë‹¤.
        num_points = 2000 # ë¼ì¸ì„ ì¡°ë°€í•˜ê²Œ ê·¸ë¦¬ê¸° ìœ„í•œ ì  ê°œìˆ˜
        x_r = torch.linspace(0, self.size_x, num_points, device=self.device) # ë¡œë´‡ ì „ë°© 0m ~ ìµœëŒ€ ê±°ë¦¬

        # ì™¼ìª½ FOV ê²½ê³„ì„  (ì´ë¯¸ì§€ u=0) -> ë¡œë´‡ ì¢Œí‘œê³„ y_r ê³„ì‚°
        # ì¹´ë©”ë¼ ì¢Œí‘œê³„: xc = -cx * zc / fx
        # ë¡œë´‡ ì¢Œí‘œê³„ ë³€í™˜(xc->-yr, zc->xr): -yr = -cx * xr / fx  => yr = (cx / fx) * xr
        y_r_left = (self.cx_tensor / self.fx_tensor) * x_r

        # ì˜¤ë¥¸ìª½ FOV ê²½ê³„ì„  (ì´ë¯¸ì§€ u=width)
        # ì¹´ë©”ë¼ ì¢Œí‘œê³„: xc = (width - cx) * zc / fx
        # ë¡œë´‡ ì¢Œí‘œê³„ ë³€í™˜: -yr = (width - cx) * xr / fx => yr = -((width - cx) / fx) * xr
        y_r_right = -((self.cam_width - self.cx_tensor) / self.fx_tensor) * x_r

        # ê·¸ë¦¬ë“œ ì¢Œí‘œë¡œ ë³€í™˜
        gx_fov = ((x_r - self.grid_origin_x_t) / self.resolution_t).long()
        gy_left = ((y_r_left - self.grid_origin_y_t) / self.resolution_t).long()
        gy_right = ((y_r_right - self.grid_origin_y_t) / self.resolution_t).long()

        # ìœ íš¨í•œ ê·¸ë¦¬ë“œ ë²”ìœ„ ë‚´ì˜ ì ë§Œ í•„í„°ë§í•˜ì—¬ ì°ê¸°
        mask_l = (gx_fov >= 0) & (gx_fov < self.cells_x) & (gy_left >= 0) & (gy_left < self.cells_y)
        self.default_bev_grid[gy_left[mask_l], gx_fov[mask_l]] = self.z_max_t

        mask_r = (gx_fov >= 0) & (gx_fov < self.cells_x) & (gy_right >= 0) & (gy_right < self.cells_y)
        self.default_bev_grid[gy_right[mask_r], gx_fov[mask_r]] = self.z_max_t

        # 6. ìµœì¢… ê¸°ë³¸ ë§µ Flatten (ì¬ì‚¬ìš©ì„ ìœ„í•´)
        self.default_bev_flat = self.default_bev_grid.flatten()

        # --- Virtual Fence ìƒì„± ë ---

        # ì¸¡ì •ìš© ì„ì‹œ ë²„í¼
        self.measured_bev_flat = torch.empty_like(self.default_bev_flat)
        self.bev_heights_flat = torch.empty_like(self.default_bev_flat) # í˜¹ì‹œ ëª°ë¼ ì¶”ê°€

        # ì¢Œí‘œ ë³€í™˜ í–‰ë ¬ (Camera -> Robot)
        self.transform_matrix = np.array([
            [0.,0.,1.,0.0],  # Cam Z -> Robot X (Forward)
            [-1.,0.,0.,0.], # Cam X -> Robot -Y (Left)
            [0.,-1.,0.,0.], # Cam Y -> Robot -Z (Up)
            [0.,0.,0.,1.]
        ], dtype=np.float32)

        self.get_logger().info('âœ… GPU íŒŒë¼ë¯¸í„° ë° Virtual Fence ì´ˆê¸°í™” ì™„ë£Œ')



    def depth_callback(self, msg):
        # ... (ê¸°ì¡´ê³¼ ë™ì¼) ...
        try:
            depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=msg.encoding).astype(np.float32) / 1000.0
            depth_tensor = torch.from_numpy(depth_image).to(self.device)
            pointcloud_cam = self.depth_to_pointcloud_gpu(depth_tensor)
            transformed_cloud = self.apply_transform_gpu(pointcloud_cam, self.transform_matrix)

            stamp = msg.header.stamp
            self.process_and_publish_pointcloud(transformed_cloud, stamp)
            self.process_and_publish_bev(transformed_cloud, stamp) # ë³€ê²½ëœ í•¨ìˆ˜ í˜¸ì¶œ

        except Exception as e:
             self.get_logger().error(f'Error: {e}')

    # ... (depth_to_pointcloud_gpu, apply_transform_gpu, process_and_publish_pointcloudëŠ” ë™ì¼) ...
    def depth_to_pointcloud_gpu(self, depth_tensor):
        z = depth_tensor
        x = (self.u_grid - self.cx_tensor) * z / self.fx_tensor 
        y = (self.v_grid - self.cy_tensor) * z / self.fy_tensor
        return torch.stack([x, y, z], dim=-1)

    def apply_transform_gpu(self, points, matrix):
        original_shape = points.shape
        points_flat = points.reshape(-1, 3)
        matrix_tensor = torch.from_numpy(matrix).to(self.device, dtype=torch.float32)
        homogeneous = torch.cat([points_flat, torch.ones((points_flat.shape[0], 1), device=self.device)], dim=1)
        transformed = torch.mm(homogeneous, matrix_tensor.T)
        return transformed[:, :3].reshape(original_shape)

    def process_and_publish_pointcloud(self, transformed_cloud, stamp):
        sampled = transformed_cloud[::self.downsample_y, ::self.downsample_x, :]
        points = sampled.reshape(-1, 3)
        points_np = points.cpu().numpy()
        if points_np.shape[0] == 0: return
        colors = np.zeros((points_np.shape[0], 3), dtype=np.uint8)
        colors[:, 0] = 200; colors[:, 1] = 100; colors[:, 2] = 200
        msg = self.create_pointcloud_msg(points_np, colors, stamp, self.target_frame)
        self.pointcloud_pub.publish(msg)

    def process_and_publish_bev(self, transformed_cloud, stamp):
        """
        BEV ë§µ ìƒì„±: FOV ë°–ì€ Occupied, ë¡œë´‡ ì˜ì—­ì€ Free, ê´€ì¸¡ëœ ì˜ì—­ì€ ì¸¡ì •ê°’ ì‚¬ìš©.
        """
        # 1. Point Cloud Flatten
        x_flat = transformed_cloud[..., 0].ravel()
        y_flat = transformed_cloud[..., 1].ravel()
        z_flat = transformed_cloud[..., 2].ravel()

        # 2. ìœ íš¨í•œ í¬ì¸íŠ¸ í•„í„°ë§ (ë†’ì´ ë° ê·¸ë¦¬ë“œ ë²”ìœ„)
        mask = (z_flat > self.z_min_t) & (z_flat < self.z_max_t)
        grid_c = ((x_flat - self.grid_origin_x_t) / self.resolution_t).long()
        grid_r = ((y_flat - self.grid_origin_y_t) / self.resolution_t).long()
        mask &= (grid_c >= 0) & (grid_c < self.cells_x) & \
                (grid_r >= 0) & (grid_r < self.cells_y)

        valid_z = z_flat[mask]
        valid_r = grid_r[mask]
        valid_c = grid_c[mask]

        # 3. [í•µì‹¬ ë³€ê²½] ê¸°ë³¸ ë§µ ë³µì‚¬ (FOV ë°–=Occupied, ë¡œë´‡=Free ìƒíƒœ)
        # ë§¤ í”„ë ˆì„ë§ˆë‹¤ final_bev_flatì„ default ìƒíƒœë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
        final_bev_flat = self.default_bev_flat.clone()

        # ê´€ì¸¡ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë®ì–´ì“°ê¸° ì§„í–‰
        if valid_z.shape[0] > 0:
            linear_indices = valid_r * self.cells_x + valid_c

            # 4. í˜„ì¬ í”„ë ˆì„ ì¸¡ì •ê°’ ê³„ì‚°
            # ì¸¡ì •ìš© ë²„í¼ë¥¼ -infë¡œ ì´ˆê¸°í™” (ê´€ì¸¡ë˜ì§€ ì•ŠìŒì„ ì˜ë¯¸)
            self.measured_bev_flat.fill_(-torch.inf)
            
            # ê´€ì¸¡ëœ ìœ„ì¹˜ ì¤‘ ê°€ì¥ ë†’ì€ ê°’(amax) ì €ì¥
            self.measured_bev_flat.index_reduce_(
                dim=0,
                index=linear_indices,
                source=valid_z, 
                reduce="amax",
                include_self=False
            )

            # 5. ê¸°ë³¸ ë§µ ìœ„ì— ì¸¡ì •ê°’ ë®ì–´ì“°ê¸°
            # ì¸¡ì •ëœ ê°’(-infê°€ ì•„ë‹Œ ê°’)ì´ ìˆëŠ” ì…€ë§Œ ë§ˆìŠ¤í‚¹
            observed_mask = self.measured_bev_flat > -torch.inf
            # í•´ë‹¹ ì…€ë“¤ì„ ì¸¡ì •ëœ ì‹¤ì œ ë†’ì´ ê°’ìœ¼ë¡œ êµì²´
            final_bev_flat[observed_mask] = self.measured_bev_flat[observed_mask]

        # --- ì´í•˜ ë°œí–‰ ë¡œì§ì€ ë™ì¼í•˜ì§€ë§Œ, final_bev_flatì„ ì‚¬ìš© ---
        
        # BEV ì „ì²´ë¥¼ ë°œí–‰í•˜ë©´ ë°ì´í„°ê°€ ë„ˆë¬´ ì»¤ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ, 
        # í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œë„ -inf(ì™„ì „ ë¯¸ì§€ì˜ ì˜ì—­)ì¸ ë¶€ë¶„ì€ ì œì™¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # í•˜ì§€ë§Œ ìš”êµ¬ì‚¬í•­ì´ "FOV ë°–ë„ Occupiedë¡œ ì±„ì›Œë‹¬ë¼"ëŠ” ê²ƒì´ë¯€ë¡œ
        # z_maxë¡œ ì±„ì›Œì§„ final_bev_flat ì „ì²´ë¥¼ ë°œí–‰í•˜ê±°ë‚˜, ê°’ì´ ìˆëŠ” ê³³ë§Œ ë°œí–‰í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” íš¨ìœ¨ì„±ì„ ìœ„í•´ Occupied(z_max) ë˜ëŠ” Free(z_min) ë˜ëŠ” ì¸¡ì •ê°’ì´ ìˆëŠ” ê³³ ëª¨ë‘ ë°œí–‰í•©ë‹ˆë‹¤.
        # (ì‚¬ì‹¤ìƒ ê·¸ë¦¬ë“œ ì „ì²´ ë°œí–‰ì´ ë  ìˆ˜ ìˆìŒ. ë¶€í•˜ê°€ í¬ë©´ ì¡°ì ˆ í•„ìš”)
        
        # ì˜ˆì‹œ: ëª¨ë“  ìœ íš¨í•œ ì…€ ë°œí–‰ (ë°°ê²½ í¬í•¨)
        # ë§Œì•½ ëŒ€ì—­í­ì´ ë¬¸ì œë¼ë©´, occupiedì¸ ë¶€ë¶„ë§Œ ë°œí–‰í•˜ëŠ” ê²ƒë„ ë°©ë²•ì…ë‹ˆë‹¤.
        valid_indices_flat = torch.arange(final_bev_flat.shape[0], device=self.device)
        height_values = final_bev_flat

        # 1D -> 2D ì¸ë±ìŠ¤
        r_idx_bev = torch.div(valid_indices_flat, self.cells_x, rounding_mode='floor')
        c_idx_bev = valid_indices_flat % self.cells_x

        # ì›”ë“œ ì¢Œí‘œ ê³„ì‚°
        x_world = self.grid_origin_x_t + (c_idx_bev.float() + 0.5) * self.resolution_t
        y_world = self.grid_origin_y_t + (r_idx_bev.float() + 0.5) * self.resolution_t
        z_world = torch.zeros_like(x_world)

        # ìƒ‰ìƒ ë³€í™˜ ë° ë©”ì‹œì§€ ìƒì„±
        rgb_float32_gpu = self._height_to_color_gpu(height_values)
        bev_data_gpu = torch.stack([x_world, y_world, z_world, rgb_float32_gpu], dim=-1)
        bev_msg = self._create_cloud_from_data(bev_data_gpu.cpu().numpy(), stamp, self.target_frame)
        self.bev_pub.publish(bev_msg)

    # ... (_height_to_color_gpu, transform_to_matrix, create_pointcloud_msg ë“± ê¸°ì¡´ ë©”ì„œë“œ ìœ ì§€) ...
    def _height_to_color_gpu(self, z):
            z_norm = (z - self.z_min_t) / self.z_range_t
            z_norm = torch.clamp(z_norm, 0.0, 1.0) * 4.0
            r = torch.zeros_like(z_norm); g = torch.zeros_like(z_norm); b = torch.zeros_like(z_norm)
            mask = z_norm < 1.0
            b[mask] = 1.0; g[mask] = z_norm[mask]
            mask = (z_norm >= 1.0) & (z_norm < 2.0)
            g[mask] = 1.0; b[mask] = 2.0 - z_norm[mask]
            mask = (z_norm >= 2.0) & (z_norm < 3.0)
            g[mask] = 1.0; r[mask] = z_norm[mask] - 2.0
            mask = z_norm >= 3.0
            r[mask] = 1.0; g[mask] = 4.0 - z_norm[mask]
            rgb_packed_gpu = ((r * 255).long() * 65536) + ((g * 255).long() * 256) + (b * 255).long()
            return rgb_packed_gpu.to(torch.uint32).view(torch.float32)

    def create_pointcloud_msg(self, points_np, colors_np, stamp, frame_id):
        header = Header(stamp=stamp, frame_id=frame_id)
        rgb_uint32 = ((colors_np[:, 0].astype(np.uint32) << 16) | (colors_np[:, 1].astype(np.uint32) << 8) | (colors_np[:, 2].astype(np.uint32)))
        pointcloud_data = np.hstack([points_np.astype(np.float32), rgb_uint32.view(np.float32).reshape(-1, 1)])
        return PointCloud2(header=header, height=1, width=pointcloud_data.shape[0], fields=self.pointcloud_fields, is_bigendian=False, point_step=self.point_step, row_step=self.point_step * pointcloud_data.shape[0], data=pointcloud_data.tobytes(), is_dense=True)

    def _create_cloud_from_data(self, point_data_np, stamp, frame_id):
        return PointCloud2(header=Header(stamp=stamp, frame_id=frame_id), height=1, width=point_data_np.shape[0], fields=self.pointcloud_fields, is_bigendian=False, point_step=self.point_step, row_step=self.point_step * point_data_np.shape[0], data=point_data_np.astype(np.float32).tobytes(), is_dense=True)

def main(args=None):
    rclpy.init(args=args)
    node = PointCloudBEVNode()
    try: rclpy.spin(node)
    except KeyboardInterrupt: pass
    finally: node.destroy_node(); rclpy.shutdown()

if __name__ == '__main__':
    main()
