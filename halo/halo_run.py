import torch
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import os
import random
import pandas as pd
#from skimage.draw import line

# --- í”„ë¡œì íŠ¸ì˜ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤ ---
from reward_estimation_dataset import NavigationDataset
#from reward_estimation_model import HALORewardModel

# ==============================================================================
# --- ğŸš€ Configuration ---
# ==============================================================================

# ### ì¤‘ìš” ###: ì•„ë˜ ê²½ë¡œë“¤ì„ ìì‹ ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
# ì‚¬ìš©í•  ë°ì´í„° ë””ë ‰í† ë¦¬
DATA_DIR = '../../data/ilrl/0903_inside_night' 
# í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
MODEL_PATH = './best_model.pth' 

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")



def generate_trajectory_mask_from_df(df, img_size):
    """
    ì†ë„ ëª…ë ¹ì´ ë‹´ê¸´ DataFrameì„ ê¸°ë°˜ìœ¼ë¡œ ìê¸° ì¤‘ì‹¬(egocentric) ê¶¤ì  ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” NavigationDatasetì˜ ë¡œì§ì„ ê°„ì†Œí™”í•˜ì—¬ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
    """
    if len(df) < 2:
        return np.zeros((img_size, img_size), dtype=np.uint8)

    # 1. Odometry ê³„ì‚°
    delta_t = df['timestamp'].diff().fillna(0) / 1000.0
    x, y, theta = 0.0, 0.0, 0.0
    odom_list = [[x, y, theta]]
    for i in range(1, len(df)):
        v = df['manual_linear_x'].iloc[i]
        w = df['manual_angular_z'].iloc[i]
        dt = delta_t.iloc[i]
        theta += w * dt
        x += v * np.cos(theta) * dt
        y += v * np.sin(theta) * dt
        odom_list.append([x, y, theta])
    odom_segment = np.array(odom_list)

    # 2. ìê¸° ì¤‘ì‹¬(Egocentric) ì¢Œí‘œê³„ë¡œ ë³€í™˜
    x0, y0, theta0 = odom_segment[0]
    coords_translated = odom_segment[:, :2] - np.array([x0, y0])
    c, s = np.cos(-theta0), np.sin(-theta0)
    rotation_matrix = np.array([[c, -s], [s, c]])
    ego_coords = (rotation_matrix @ coords_translated.T).T

    # 3. ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ì— ê¶¤ì  ê·¸ë¦¬ê¸°
    mask = np.zeros((img_size, img_size), dtype=np.uint8)
    max_range = 1.0 # ê¶¤ì  ì‹œê°í™”ë¥¼ ìœ„í•œ ê°€ìƒ ìµœëŒ€ ê±°ë¦¬

    # xì¶•(ì „ë°©)ì€ ì´ë¯¸ì§€ ë†’ì´, yì¶•(ì¢Œìš°)ì€ ì´ë¯¸ì§€ ë„ˆë¹„ì— ë§¤í•‘
    u = np.clip(((ego_coords[:, 0] / max_range) * (img_size - 1)).astype(int), 0, img_size - 1)
    v = np.clip((ego_coords[:, 1] / (max_range / 1.3) * (img_size - 1) / 2 + (img_size / 2)).astype(int), 0, img_size - 1)

    for i in range(len(u) - 1):
        rr, cc = line(u[i], v[i], u[i+1], v[i+1])
        mask[rr, cc] = 1

    mask[0, img_size // 2] = 1 # ì‹œì‘ì  í‘œì‹œ
    return mask


def generate_candidate_masks():
    """ NUM_CANDIDATE_ACTIONS ê°œìˆ˜ë§Œí¼ ë‹¤ì–‘í•œ ê³¡ë¥ ì˜ í›„ë³´ ê¶¤ì  ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. """
    angular_velocities = np.linspace(-1.0, 1.0, NUM_CANDIDATE_ACTIONS)
    candidate_masks = []

    for w in angular_velocities:
        duration = 2.0; hz = 10; num_points = int(duration * hz)
        timestamps = np.arange(num_points) * (1000 / hz)
        # íšŒì „ì´ í´ìˆ˜ë¡ ì§ì§„ ì†ë„ë¥¼ ì•½ê°„ ì¤„ì—¬ í˜„ì‹¤ì ì¸ ê¶¤ì  ìƒì„±
        linear_v = FIXED_LINEAR_V / (1 + 0.5 * abs(w))

        dummy_df = pd.DataFrame({
            'timestamp': timestamps,
            'manual_linear_x': [linear_v] * num_points,
            'manual_angular_z': [w] * num_points,
        })

        mask_np = generate_trajectory_mask_from_df(dummy_df, img_size=IMG_SIZE_MASK)
        candidate_masks.append(torch.from_numpy(mask_np).float())

    return torch.stack(candidate_masks).unsqueeze(1).to(DEVICE), angular_velocities


def main():
    print(f"Using device: {DEVICE}")

    # --- 1. ëª¨ë¸ ë¡œë“œ ---
    model = HALORewardModel(freeze_dino=True).to(DEVICE)
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"Model checkpoint not found at {MODEL_PATH}")

    # ëª¨ë¸ì˜ state_dictë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    # í•™ìŠµ ì‹œ ì €ì¥ëœ í‚¤ì™€ í˜„ì¬ ëª¨ë¸ì˜ í‚¤ê°€ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ strict=False ì˜µì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()


    # --- 3. í›„ë³´ ê¶¤ì  ë§ˆìŠ¤í¬ ìƒì„± ---
    candidate_masks, angular_velocities = generate_candidate_masks()


    with torch.no_grad():
            # ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ í›„ë³´ ê¶¤ì  ê°œìˆ˜(K)ë§Œí¼ ë³µì œí•˜ì—¬ ë°°ì¹˜ ìƒì„±
            rgb_expanded = rgb_tensor_inf.repeat(NUM_CANDIDATE_ACTIONS, 1, 1, 1)

            # ëª¨ë“  í›„ë³´ ì•¡ì…˜ì— ëŒ€í•œ ë³´ìƒê³¼ ê±°ë¦¬ ë™ì‹œ ì˜ˆì¸¡
            predicted_rewards, predicted_depths = model(rgb_expanded, candidate_masks)

            # ê°€ì¥ ë³´ìƒì´ ë†’ì€ ì•¡ì…˜ í•˜ë‚˜ì— ëŒ€í•œ ê±°ë¦¬ ì˜ˆì¸¡ê°’ë§Œ ì‚¬ìš©
            # (ëª¨ë“  ì•¡ì…˜ì— ëŒ€í•´ ë™ì¼í•œ ì´ë¯¸ì§€ì´ë¯€ë¡œ ê±°ë¦¬ ì˜ˆì¸¡ê°’ì€ ê±°ì˜ ë™ì¼í•¨)
            predicted_dist = predicted_depths[0].cpu().numpy()
            rewards = predicted_rewards.squeeze().cpu().numpy()

        # --- 5. ì‹œê°í™” ---
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

        # ì™¼ìª½: ì›ë³¸ RGB ì´ë¯¸ì§€
        ax1.imshow(rgb_tensor_disp.permute(1, 2, 0))
        ax1.set_title(f"Input Image (Sample #{random_idx})")
        ax1.axis('off')

        # ì˜¤ë¥¸ìª½: ë³´ìƒ ë° ê±°ë¦¬ ë¹„êµ ê·¸ë˜í”„
        ax2.set_title('Reward vs. Distance Analysis')
        ax2.set_xlabel('Angular Velocity (rad/s)')

        # íŒŒë€ìƒ‰ ë§‰ëŒ€: ì˜ˆì¸¡ëœ ë³´ìƒ (ì™¼ìª½ Yì¶•)
        color_reward = 'cornflowerblue'
        ax2.set_ylabel('Predicted Reward', color=color_reward, fontsize=12)
        ax2.bar(angular_velocities, rewards, width=0.1, color=color_reward, alpha=0.9, label='Predicted Reward')
        ax2.tick_params(axis='y', labelcolor=color_reward)

        # ì˜¤ë¥¸ìª½ Yì¶•ì„ ê³µìœ í•˜ëŠ” ë‘ ë²ˆì§¸ ì¶• ìƒì„±
        ax3 = ax2.twinx()
        ax3.set_ylabel('Normalized Distance (1=Far)', fontsize=12)
        ax3.set_ylim(-0.05, 1.1)

        # ë¹¨ê°„ìƒ‰ ì ì„ : ì‹¤ì œ(Ground-Truth) ê±°ë¦¬
        distance_x_coords = np.linspace(angular_velocities.min(), angular_velocities.max(), NUM_DEPTH_BINS)
        ax3.plot(distance_x_coords, ground_truth_dist, color='crimson', marker='o', linestyle='--', label='Ground-Truth Distance')

        # ì´ˆë¡ìƒ‰ ì‹¤ì„ : ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê±°ë¦¬
        ax3.plot(distance_x_coords, predicted_dist, color='limegreen', marker='x', linestyle='-', label='Predicted Distance')

        # ë²”ë¡€(legend)ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        lines, labels = ax2.get_legend_handles_labels()
        lines2, labels2 = ax3.get_legend_handles_labels()
        ax3.legend(lines + lines2, labels + labels2, loc='upper center')

        fig.tight_layout()
        plt.show()
