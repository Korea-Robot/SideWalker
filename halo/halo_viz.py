# íŒŒì¼ëª…: model_inference_viz.py

import torch
import numpy as np
import matplotlib.pyplot as plt
import os
import random
import pandas as pd
import time

# skimage ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜: pip install scikit-image
from skimage.draw import line

# ë³„ë„ íŒŒì¼ë¡œë¶€í„° ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
from reward_estimation_model import HALORewardModel

# ==============================================================================
# --- ğŸš€ Configuration ---
# ==============================================================================
MODEL_PATH = './best_model.pth'
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_CANDIDATE_ACTIONS = 21
FIXED_LINEAR_V = 0.5
IMG_SIZE_MASK = 224
IMG_SIZE_RGB = 224
NUM_DEPTH_BINS = 25

# ==============================================================================
# --- ê¶¤ì  ìƒì„± í•¨ìˆ˜ë“¤ (ì›ë³¸ ìœ ì§€) ---
# ==============================================================================
def generate_trajectory_mask_from_df(df, img_size):
    if len(df) < 2: return np.zeros((img_size, img_size), dtype=np.uint8)
    delta_t = df['timestamp'].diff().fillna(0) / 1000.0
    x, y, theta = 0.0, 0.0, 0.0
    odom_list = [[x, y, theta]]
    for i in range(1, len(df)):
        v = df['manual_linear_x'].iloc[i]; w = df['manual_angular_z'].iloc[i]; dt = delta_t.iloc[i]
        theta += w * dt; x += v * np.cos(theta) * dt; y += v * np.sin(theta) * dt
        odom_list.append([x, y, theta])
    odom_segment = np.array(odom_list)
    x0, y0, theta0 = odom_segment[0]
    coords_translated = odom_segment[:, :2] - np.array([x0, y0])
    c, s = np.cos(-theta0), np.sin(-theta0)
    rotation_matrix = np.array([[c, -s], [s, c]])
    ego_coords = (rotation_matrix @ coords_translated.T).T
    mask = np.zeros((img_size, img_size), dtype=np.uint8)
    max_range = 1.0
    u = np.clip(((ego_coords[:, 0] / max_range) * (img_size - 1)).astype(int), 0, img_size - 1)
    v = np.clip((ego_coords[:, 1] / (max_range / 1.3) * (img_size - 1) / 2 + (img_size / 2)).astype(int), 0, img_size - 1)
    for i in range(len(u) - 1):
        rr, cc = line(u[i], v[i], u[i+1], v[i+1])
        mask[rr, cc] = 1
    mask[0, img_size // 2] = 1
    return mask

def generate_candidate_masks():
    angular_velocities = np.linspace(-1.0, 1.0, NUM_CANDIDATE_ACTIONS)
    candidate_masks = []
    for w in angular_velocities:
        duration = 2.0; hz = 10; num_points = int(duration * hz)
        timestamps = np.arange(num_points) * (1000 / hz)
        linear_v = FIXED_LINEAR_V / (1 + 0.5 * abs(w))
        dummy_df = pd.DataFrame({'timestamp': timestamps, 'manual_linear_x': [linear_v] * num_points, 'manual_angular_z': [w] * num_points})
        mask_np = generate_trajectory_mask_from_df(dummy_df, img_size=IMG_SIZE_MASK)
        candidate_masks.append(torch.from_numpy(mask_np).float())
    return torch.stack(candidate_masks).unsqueeze(1).to(DEVICE), angular_velocities

# ==============================================================================
# --- ğŸš€ Main Execution ---
# ==============================================================================
def main():
    print(f"Using device: {DEVICE}")

    # --- 1. ëª¨ë¸ ë° í›„ë³´ ê¶¤ì  ë¡œë“œ (í•œ ë²ˆë§Œ ìˆ˜í–‰) ---
    model = HALORewardModel(freeze_dino=True).to(DEVICE)
    if os.path.exists(MODEL_PATH):
        print(f"'{MODEL_PATH}' ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    else:
        print(f"ê²½ê³ : '{MODEL_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ˆê¸°í™”ëœ ëª¨ë¸ë¡œ ê³„ì†í•©ë‹ˆë‹¤.")
    model.eval()

    candidate_masks, angular_velocities = generate_candidate_masks()

    # --- 2. Matplotlib ëŒ€í™”í˜• ëª¨ë“œ ì„¤ì • ---
    plt.ion() # ëŒ€í™”í˜• ëª¨ë“œ ì¼œê¸°
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))
    print("ì‹¤ì‹œê°„ ì‹œê°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¤‘ì§€í•˜ë ¤ë©´ í„°ë¯¸ë„ì—ì„œ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")

    # --- 3. ì‹¤ì‹œê°„ ì¶”ë¡  ë° ì‹œê°í™” ë£¨í”„ ---
    try:
        while True:
            # --- ê°€ìƒ ë°ì´í„° ì‹¤ì‹œê°„ ìƒì„± (ì‹¤ì œ ì‚¬ìš© ì‹œ ì¹´ë©”ë¼ ë°ì´í„°ë¡œ ëŒ€ì²´) ---
            random_idx = random.randint(0, 1000)
            rgb_tensor_disp = torch.rand(3, IMG_SIZE_RGB, IMG_SIZE_RGB)
            rgb_tensor_inf = rgb_tensor_disp.unsqueeze(0).to(DEVICE)
            # Ground-truth ê±°ë¦¬ê°€ ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ê²Œ í•¨
            phase_shift = time.time() * 2
            ground_truth_dist = np.cos(np.linspace(0, np.pi * 2, NUM_DEPTH_BINS) + phase_shift) * 0.4 + 0.5

            # --- ëª¨ë¸ ì¶”ë¡  ---
            with torch.no_grad():
                rgb_expanded = rgb_tensor_inf.repeat(NUM_CANDIDATE_ACTIONS, 1, 1, 1)
                predicted_rewards, predicted_depths = model(rgb_expanded, candidate_masks)
                predicted_dist = predicted_depths[0].cpu().numpy()
                rewards = predicted_rewards.squeeze().cpu().numpy()

            # --- ì‹œê°í™” ì—…ë°ì´íŠ¸ ---
            # ì´ì „ í”„ë ˆì„ì˜ ë‚´ìš© ì§€ìš°ê¸°
            ax1.cla()
            ax2.cla()
            # twinx()ë¡œ ìƒì„±ëœ ì„¸ ë²ˆì§¸ ì¶•ë„ ìˆ˜ë™ìœ¼ë¡œ ì§€ì›Œì•¼ í•¨
            if 'ax3' in locals() and ax3.figure == fig:
                ax3.remove()

            # ì™¼ìª½: RGB ì´ë¯¸ì§€
            ax1.imshow(rgb_tensor_disp.permute(1, 2, 0))
            ax1.set_title(f"Input Image (Frame #{random_idx})")
            ax1.axis('off')

            # ì˜¤ë¥¸ìª½: ë³´ìƒ ë° ê±°ë¦¬ ë¹„êµ ê·¸ë˜í”„
            ax2.set_title('Reward vs. Distance Analysis')
            ax2.set_xlabel('Angular Velocity (rad/s)')
            
            color_reward = 'cornflowerblue'
            ax2.set_ylabel('Predicted Reward', color=color_reward, fontsize=12)
            ax2.bar(angular_velocities, rewards, width=0.1, color=color_reward, alpha=0.9, label='Predicted Reward')
            ax2.tick_params(axis='y', labelcolor=color_reward)
            
            ax3 = ax2.twinx()
            ax3.set_ylabel('Normalized Distance (1=Far)', fontsize=12)
            ax3.set_ylim(-0.05, 1.1)
            
            distance_x_coords = np.linspace(angular_velocities.min(), angular_velocities.max(), NUM_DEPTH_BINS)
            ax3.plot(distance_x_coords, ground_truth_dist, color='crimson', marker='o', linestyle='--', label='Ground-Truth Distance')
            ax3.plot(distance_x_coords, predicted_dist, color='limegreen', marker='x', linestyle='-', label='Predicted Distance')
            
            lines, labels = ax2.get_legend_handles_labels()
            lines2, labels2 = ax3.get_legend_handles_labels()
            ax3.legend(lines + lines2, labels + labels2, loc='upper center')
            
            fig.tight_layout()
            
            # ê·¸ë˜í”„ ì°½ì„ ì—…ë°ì´íŠ¸í•˜ê³  ì ì‹œ ëŒ€ê¸°
            plt.pause(0.1)

    except KeyboardInterrupt:
        print("\nì‹œê°í™”ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    finally:
        plt.ioff() # ëŒ€í™”í˜• ëª¨ë“œ ë„ê¸°
        print("ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë³´ë ¤ë©´ ì°½ì„ ë‹«ìœ¼ì„¸ìš”.")
        plt.show() # ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë³´ì—¬ì£¼ê³  ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ ëŒ€ê¸°

if __name__ == '__main__':
    main()
