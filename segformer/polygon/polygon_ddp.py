# train_ddp.py - DDP ë²„ì „

import os
import argparse
import json
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from transformers import SegformerForSemanticSegmentation
import wandb
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import cv2

# ì´ì „ ë‹¨ê³„ì—ì„œ ì‘ì„±í•œ PolygonSegmentationDataset í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from polygon_dataset import PolygonSegmentationDataset


os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
# os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2"  # ì¤‘ë³µ ì œê±°
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2"  # ì¤‘ë³µ ì œê±°
os.environ["NCCL_P2P_DISABLE"] = '1'  # GPU P2P í†µì‹  ë”

def setup_ddp(rank, world_size):
    """DDP í™˜ê²½ ì„¤ì •"""
    # os.environ['MASTER_ADDR'] = 'localhost'
    # os.environ['MASTER_PORT'] = '12355'
    # os.environ['NCCL_P2P_DISABLE'] = '1'
    # CUDA_VISIBLE_DEVICESë¡œ ì„¤ì •ëœ GPUë“¤ì€ PyTorchì—ì„œ 0, 1ë¡œ ë§¤í•‘ë¨
    # ì‹¤ì œ GPU 0, 3 -> PyTorchì—ì„œ 0, 1
    local_gpu = rank
    
    # CUDA ë””ë°”ì´ìŠ¤ ì„¤ì •
    torch.cuda.set_device(local_gpu)
    
    # í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ ì´ˆê¸°í™”
    dist.init_process_group(
        backend='nccl',
        init_method='env://',
        world_size=world_size,
        rank=rank
    )
    
    return local_gpu

def cleanup():
    """DDP í™˜ê²½ ì •ë¦¬"""
    dist.destroy_process_group()

def create_colormap(num_classes):
    """í´ë˜ìŠ¤ë³„ ê³ ìœ  ìƒ‰ìƒ ìƒì„±"""
    colors = []
    for i in range(num_classes):
        # HSV ìƒ‰ê³µê°„ì—ì„œ ê· ë“±í•˜ê²Œ ë¶„í¬ëœ ìƒ‰ìƒ ìƒì„±
        hue = i / num_classes
        saturation = 0.8
        value = 0.9
        
        # HSVë¥¼ RGBë¡œ ë³€í™˜
        c = value * saturation
        x = c * (1 - abs((hue * 6) % 2 - 1))
        m = value - c
        
        if hue < 1/6:
            r, g, b = c, x, 0
        elif hue < 2/6:
            r, g, b = x, c, 0
        elif hue < 3/6:
            r, g, b = 0, c, x
        elif hue < 4/6:
            r, g, b = 0, x, c
        elif hue < 5/6:
            r, g, b = x, 0, c
        else:
            r, g, b = c, 0, x
            
        colors.append([r + m, g + m, b + m])
    
    # ë°°ê²½ì€ ê²€ì€ìƒ‰ìœ¼ë¡œ
    colors[0] = [0, 0, 0]
    
    return ListedColormap(colors)

def visualize_predictions(model, valid_loader, device, epoch, save_dir="validation_results", num_samples=4, rank=0):
    """ê²€ì¦ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  ì €ì¥ (rank 0ì—ì„œë§Œ ì‹¤í–‰)"""
    if rank != 0:
        return
        
    model.eval()
    
    os.makedirs(save_dir, exist_ok=True)
    
    colormap = create_colormap(30)  # num_labels í•˜ë“œì½”ë”©
    
    with torch.no_grad():
        for batch_idx, data in enumerate(valid_loader):
            if batch_idx >= num_samples:  # ì§€ì •ëœ ìˆ˜ë§Œí¼ë§Œ ì‹œê°í™”
                break
                
            images = data['pixel_values'].to(device)
            masks = data['labels'].to(device)
            
            # ì¶”ë¡  - SegFormer ëª¨ë¸ë¡œ ì˜ˆì¸¡
            inputs = {'pixel_values': images}
            outputs = model(**inputs)
            logits = outputs.logits
            
            upsampled_logits = F.interpolate(
                logits,
                size=masks.shape[-2:],
                mode='bilinear',
                align_corners=False
            )
            
            predictions = torch.argmax(upsampled_logits, dim=1)
            
            # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì‹œê°í™”
            img = images[0].cpu().numpy().transpose(1, 2, 0)
            gt_mask = masks[0].cpu().numpy()
            pred_mask = predictions[0].cpu().numpy()
            
            # ì´ë¯¸ì§€ ì •ê·œí™” í•´ì œ (0-1 ë²”ìœ„ë¡œ)
            img = (img - img.min()) / (img.max() - img.min())
            
            # ì„œë¸Œí”Œë¡¯ ìƒì„±
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            # ì›ë³¸ ì´ë¯¸ì§€
            axes[0].imshow(img)
            axes[0].set_title('Original Image')
            axes[0].axis('off')
            
            # Ground Truth
            axes[1].imshow(gt_mask, cmap=colormap, vmin=0, vmax=29)
            axes[1].set_title('Ground Truth')
            axes[1].axis('off')
            
            # Prediction
            axes[2].imshow(pred_mask, cmap=colormap, vmin=0, vmax=29)
            axes[2].set_title('Prediction')
            axes[2].axis('off')
            
            plt.tight_layout()
            
            # ì €ì¥
            save_path = os.path.join(save_dir, f"loss_epoch_{epoch+1}_sample_{batch_idx+1}.png")
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"Validation visualization saved: {save_path}")

def validate_model(model, valid_loader, device):
    """ê²€ì¦ í•¨ìˆ˜ - SegFormer ë‚´ì¥ loss ì‚¬ìš©"""
    model.eval()
    val_loss = 0.0
    correct_pixels = 0
    total_pixels = 0
    
    with torch.no_grad():
        for val_data in valid_loader:
            val_imgs = val_data['pixel_values'].to(device)
            val_masks = val_data['labels'].to(device)
            
            # SegFormer ëª¨ë¸ ì§ì ‘ ì‚¬ìš©
            val_inputs = {
                'pixel_values': val_imgs,
                'labels': val_masks
            }
            val_outputs = model(**val_inputs)
            
            loss = val_outputs.loss
            val_loss += loss.item()
            
            # ì˜ˆì¸¡ ê²°ê³¼ ê³„ì‚°
            val_logits = val_outputs.logits
            val_upsampled = F.interpolate(
                val_logits,
                size=val_masks.shape[-2:],
                mode='bilinear',
                align_corners=False
            )
            
            # ì •í™•ë„ ê³„ì‚°
            preds = torch.argmax(val_upsampled, dim=1)
            correct_pixels += (preds == val_masks).sum().item()
            total_pixels += val_masks.numel()
    
    avg_val_loss = val_loss / len(valid_loader)
    pixel_accuracy = correct_pixels / total_pixels
    
    return avg_val_loss, pixel_accuracy

def main(rank, world_size):
    """ë©”ì¸ í•™ìŠµ í•¨ìˆ˜"""
    
    # DDP ì„¤ì •
    local_gpu = setup_ddp(rank, world_size)
    device = torch.device(f'cuda:{local_gpu}')
    
    # ìƒìˆ˜ ì •ì˜
    ROOT_DIRECTORY = "/home/work/data/indo_walking/polygon_segmentation"
    CLASS_MAPPING_FILE = os.path.join(ROOT_DIRECTORY, 'class_mapping.json')
    
    # í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
    try:
        with open(CLASS_MAPPING_FILE, 'r', encoding='utf-8') as f:
            class_info = json.load(f)
    except FileNotFoundError:
        if rank == 0:
            print(f"ğŸš¨ í´ë˜ìŠ¤ ë§¤í•‘ íŒŒì¼('{CLASS_MAPPING_FILE}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        cleanup()
        return
    
    # í´ë˜ìŠ¤ ë§¤í•‘
    class_to_idx = {
        'background': 0,
        'barricade': 1,
        'bench': 2,
        'bicycle': 3,
        'bollard': 4,
        'bus': 5,
        'car': 6,
        'carrier': 7,
        'cat': 8,
        'chair': 9,
        'dog': 10,
        'fire_hydrant': 11,
        'kiosk': 12,
        'motorcycle': 13,
        'movable_signage': 14,
        'parking_meter': 15,
        'person': 16,
        'pole': 17,
        'potted_plant': 18,
        'power_controller': 19,
        'scooter': 20,
        'stop': 21,
        'stroller': 22,
        'table': 23,
        'traffic_light': 24,
        'traffic_light_controller': 25,
        'traffic_sign': 26,
        'tree_trunk': 27,
        'truck': 28,
        'wheelchair': 29
    }
    
    id2label = {int(idx): label for label, idx in class_to_idx.items()}
    label2id = class_to_idx
    num_labels = len(id2label)
    
    if rank == 0:
        print(f"í´ë˜ìŠ¤ ìˆ˜: {num_labels}")
        print(f"í´ë˜ìŠ¤ ë ˆì´ë¸”: {id2label}")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = PolygonSegmentationDataset(root_dir=ROOT_DIRECTORY, is_train=True)
    valid_dataset = PolygonSegmentationDataset(root_dir=ROOT_DIRECTORY, is_train=False)
    
    # DDPìš© ìƒ˜í”ŒëŸ¬ ìƒì„±
    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)
    valid_sampler = DistributedSampler(valid_dataset, num_replicas=world_size, rank=rank)
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    batch_size = 64  # DDPì—ì„œëŠ” ì´ ë°°ì¹˜ í¬ê¸°ê°€ 32 * 2 = 64ê°€ ë¨
    num_workers = 8  # worker ìˆ˜ ì¡°ì •
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        sampler=train_sampler,
        num_workers=num_workers, 
        pin_memory=True
    )
    
    valid_loader = DataLoader(
        valid_dataset, 
        batch_size=batch_size, 
        sampler=valid_sampler,
        num_workers=num_workers, 
        pin_memory=True
    )
    
    # ëª¨ë¸ ìƒì„±
    model = SegformerForSemanticSegmentation.from_pretrained(
        "nvidia/mit-b0",
        num_labels=num_labels,
        ignore_mismatched_sizes=True
    )
    model.to(device)
    
    # DDP ë˜í•‘
    model = DDP(model, device_ids=[local_gpu], output_device=local_gpu)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    epochs = 100
    lr = 5e-5
    weight_decay = 1e-4
    
    # ì˜µí‹°ë§ˆì´ì €
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    
    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    # WandB ì´ˆê¸°í™” (rank 0ì—ì„œë§Œ)
    if rank == 0:
        wandb.init(project="segmentation_project", name=f"ddp_run_0707")
    
    # í•™ìŠµ ë£¨í”„
    best_val_loss = float('inf')
    
    for epoch in range(epochs):
        # ìƒ˜í”ŒëŸ¬ epoch ì„¤ì • (ì¤‘ìš”!)
        train_sampler.set_epoch(epoch)
        
        model.train()
        running_loss = 0.0
        
        for i, data in enumerate(train_loader):
            images = data['pixel_values'].to(device)
            masks = data['labels'].to(device)
            
            # SegFormer ëª¨ë¸ ì…ë ¥ êµ¬ì„±
            inputs = {
                'pixel_values': images,
                'labels': masks
            }
            
            # ìˆœì „íŒŒ
            outputs = model(**inputs)
            
            # SegFormer ë‚´ì¥ loss ì‚¬ìš©
            loss = outputs.loss
            
            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            
            if (i + 1) % 50 == 0 and rank == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}")
        
        # ê²€ì¦ (ëª¨ë“  GPUì—ì„œ ì‹¤í–‰)
        val_loss, pixel_acc = validate_model(model, valid_loader, device)
        
        # ê²°ê³¼ ìˆ˜ì§‘ (all_reduce)
        val_loss_tensor = torch.tensor(val_loss, device=device)
        pixel_acc_tensor = torch.tensor(pixel_acc, device=device)
        
        dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)
        dist.all_reduce(pixel_acc_tensor, op=dist.ReduceOp.SUM)
        
        val_loss = val_loss_tensor.item() / world_size
        pixel_acc = pixel_acc_tensor.item() / world_size
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        # í‰ê·  ì†ì‹¤ ê³„ì‚°
        avg_train_loss = running_loss / len(train_loader)
        
        # ê²€ì¦ ê²°ê³¼ ì‹œê°í™” (rank 0ì—ì„œë§Œ)
        if rank == 0:
            visualize_predictions(model.module, valid_loader, device, epoch, 
                                 save_dir="validation_results", num_samples=4, rank=rank)
            
            # WandB ë¡œê¹…
            wandb.log({
                "epoch": epoch + 1,
                "train_loss": avg_train_loss,
                "val_loss": val_loss,
                "pixel_accuracy": pixel_acc,
                "learning_rate": scheduler.get_last_lr()[0]
            })
            
            print(f"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Pixel Acc: {pixel_acc:.4f}")
        
        # ëª¨ë¸ ì €ì¥ (rank 0ì—ì„œë§Œ)
        if rank == 0:
            # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs("ckpts", exist_ok=True)
            
            # ëª¨ë¸ ì €ì¥
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(model.module.state_dict(), f"ckpts/best_seg_model.pth")
                print(f"Best ëª¨ë¸ ì €ì¥! Val Loss: {val_loss:.4f}")
            
            # ì •ê¸°ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (epoch + 1) % 10 == 0:
                torch.save(model.module.state_dict(), f"ckpts/seg_model_epoch_{epoch+1}.pth")
    
    if rank == 0:
        print("í•™ìŠµ ì™„ë£Œ!")
        wandb.finish()
    
    cleanup()

if __name__ == "__main__":
    # ì‚¬ìš©í•  GPU ìˆ˜ ì„¤ì • (0ë²ˆ, 3ë²ˆ GPU)
    world_size = 3
    
    # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ DDP ì‹¤í–‰
    import torch.multiprocessing as mp
    mp.spawn(main, args=(world_size,), nprocs=world_size, join=True)